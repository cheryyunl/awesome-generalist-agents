# Awesome-Generalist-Agents [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) [![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com)

A curated list of papers for generalist AI agents in both virtual and physical worlds.

- [Awesome-Generalist-Agents](#awesome-generalist-agents)
  - [Foundation Generalist Models](#foundation-generalist-models)
  - [Generalist Agents in Both Virtual and Physical Worlds](#generalist-agents-in-both-virtual-and-physical-worlds)
  - [Generalist Embodied Agents](#embodied-agents)
  - [Generalist Web Agents](#generalist-web-agents)
  - [Datasets & Benchmarks](#datasets-&-benchmarks)

---

## Generalist Agents in Both Virtual and Physical Worlds
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| May 2022 | Gato | [A Generalist Agent](https://arxiv.org/abs/2205.06175) | TMLR'22 | [Report](https://deepmind.google/discover/blog/a-generalist-agent/) |


## Generalist Embodied Agents
### Vision-Language-Action (VLA) Models
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Dec 2022 | RT-1 | [RT-1: Robotics Transformer for Real-World Control at Scale](https://arxiv.org/abs/2406.09246) | RSS'23 | [Project](https://robotics-transformer1.github.io/) |
| July 2023 | RT-2 | [RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control](https://arxiv.org/abs/2307.15818) | ArXiv'23 | [Project](https://robotics-transformer2.github.io/) |
| Nov 2023 | LEO | [An embodied generalist agent in 3d world](https://arxiv.org/abs/2311.12871) | ICML'24 | [Project](https://embodied-generalist.github.io/) |
| Mar 2024 | 3D-VLA | [3D-VLA: A 3D Vision-Language-Action Generative World Model](https://arxiv.org/abs/2403.09631) | ICML'24 | [Project](https://vis-www.cs.umass.edu/3dvla) |
| May 2024 | Octo | [Octo: An Open-Source Generalist Robot Policy](https://arxiv.org/abs/2403.09618) | ArXiv'24 | [Project](https://octo-models.github.io/) |
| June 2024 | OpenVLA | [OpenVLA: An Open-Source Vision-Language-Action Model](https://arxiv.org/abs/2406.09246) | CORL'24 | [Project](https://openvla.github.io/) |

### Generalist Policies

### Multimodal World Models




## Generlist Web Agents
### Generalist Agents for Simulated Worlds
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Feb 2024 | Agent-Pro | [Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization](https://arxiv.org/abs/2402.17574) | ACL'24 | [Project](https://github.com/zwq2018/Agent-Pro) |
| Mar 2024 | SIMA | [Scaling Instructable Agents Across Many Simulated Worlds](https://arxiv.org/abs/2404.10179) | ArXiv'24 | [Report](https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/?utm_source=twitter&utm_medium=social&utm_campaign=SIMA/) |




### Generalist Agents for Realistic Tasks
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Feb 2023 | Toolformer | [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761) | NeurIPS'23 | [Project]() |
| Mar 2023 | RCI | [Language Models can Solve Computer Tasks](https://arxiv.org/abs/2303.17491) | ArXiv'23 | [Project](https://posgnu.github.io/rci-web/) |
| Mar 2023 | HuggingGPT | [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580) | ArXiv'23 | [Project](https://huggingface.co/spaces/microsoft/HuggingGPT) |
| May 2023 | Pix2Act | [From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces](https://arxiv.org/abs/2306.00245) | NeurIPS'23 | [Project](https://github.com/google-deepmind/pix2act) |
| Jul 2023 | WebAgent | [A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis](https://arxiv.org/abs/2307.12856) | ICLR'24 | [Project]() |
| Sep 2023 | LASER | [LLM Agent with State-Space Exploration for Web Navigation](https://arxiv.org/abs/2309.08172) | ArXiv'23 | [Project]([https://github.com/laser-agent/laser](https://github.com/Mayer123/LASER)) |
| Sep 2023 | Auto-GUI | [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://arxiv.org/abs/2309.11436) | ACL'24 | [Project](https://github.com/cooelf/Auto-GUI) |
| Dec 2023 | CogAgent | [CogAgent: A Visual Language Model for GUI Agents](https://arxiv.org/abs/2312.08914) | CVPR'24 | [Project](https://github.com/THUDM/CogAgent) |
| Dec 2023 | AppAgent | [AppAgent: Multimodal Agents as Smartphone Users](https://arxiv.org/abs/2312.13771) | ArXiv'23 | [Project](https://appagent-official.github.io/) |
| Dec 2023 | CLOVA | [CLOVA: A Closed-LOop Visual Assistant with Tool Usage and Update](https://arxiv.org/abs/2312.10908) | CVPR 2024 | [Project](https://clova-tool.github.io/) |
| Jan 2024 | SeeAct | [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://arxiv.org/abs/2401.01614) | ICML'24 | [Project](https://osu-nlp-group.github.io/SeeAct/) |
| Jan 2024 | Mobile-Agent | [Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://arxiv.org/abs/2401.16158) | ArXiv'24 | [Project](https://github.com/X-PLUG/MobileAgent) |
| Jan 2024 | WebVoyager | [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://arxiv.org/abs/2401.13919) | ACL'24 | [Project](https://github.com/web-voyager/webvoyager) |
| Jan 2024 | SeeClick | [SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents](https://arxiv.org/abs/2401.10935) | ArXiv'24 | [Project](https://github.com/njucckevin/SeeClick)|
| Oct 2024 | OS-ATLAS | [OS-ATLAS: A Foundation Action Model for Generalist GUI Agents](https://arxiv.org/abs/2410.23218) | ArXiv'24 | [Project](https://osatlas.github.io/) |




## Datasets & Benchmarks
### For Embodied Agents


### For Web Agents
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Jul 2022 | WebShop | [Towards Scalable Real-World Web Interaction with Grounded Language Agents](https://arxiv.org/abs/2207.01206) | NeurIPS'22 | [Project](https://webshop-pnlp.github.io/) |
| May 2023 | Mobile-Env | [Mobile-Env: An Evaluation Platform and Benchmark for Interactive Agents in LLM Era](https://arxiv.org/abs/2305.08144) | ArXiv'23 | [Project](https://github.com/X-LANCE/Mobile-Env) | 
| Jun 2023 | Mind2Web | [Mind2Web: Towards a Generalist Agent for the Web](https://arxiv.org/abs/2306.06070) | NeurIPS'23 | [Project](https://osu-nlp-group.github.io/Mind2Web/) |
| Jul 2023 | WebArena | [WebArena: A Realistic Web Environment for Building Autonomous Agents](https://arxiv.org/abs/2307.13854) | ICLR'24 | [Project](https://webarena.dev/) |
| Jul 2023 | ToolBench | [ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs](https://arxiv.org/abs/2307.16789) | ICLR'24 | [Project](https://github.com/OpenBMB/ToolBench) |
| Jul 2023 | AITW | [Android in the Wild: A Large-Scale Dataset for Android Device Control](https://arxiv.org/abs/2307.10088) | ArXiv'23 | [Project](https://github.com/google-research/google-research/tree/master/android_in_the_wild) |
| Jan 2024 | VWA | [Visualwebarena: Evaluating multimodal agents on realistic visual web tasks](https://arxiv.org/abs/2401.13649) | ACL'2024 | [Project](https://jykoh.com/vwa) |
| Feb 2024 | TravelPlanner | [Travelplanner: A benchmark for real-world planning with language agents](https://arxiv.org/abs/2402.01622) | ICML'2024 | [Project](https://osu-nlp-group.github.io/TravelPlanner/) |
| Apr 2024 | OSWorld | [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://arxiv.org/abs/2404.07864) | ArXiv'24 | [Project](https://os-world.github.io/) |


### General Benchmarks
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Aug 2024 | VisualAgentBench | [VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents](https://arxiv.org/abs/2408.06327) | ArXiv'24 | [Project](https://github.com/THUDM/VisualAgentBench/tree/main) |



## ðŸŒ·
We always welcome contributions. If you find any interesting papers that are not included in this collection, feel free to open a pull request.

For any questions or suggestions, please contact [Yongyuan Liang](https://cheryyunl.github.io/) or [Ruihan Yang](https://rchalyang.github.io/).
