# Awesome-Generalist-Agents [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) [![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com)

A curated list of papers for generalist AI agents in both virtual and physical worlds.

- [Awesome-Generalist-Agents](#awesome-generalist-agents)
  - [Generalist Agents in Both Virtual and Physical Worlds](#generalist-agents-in-both-virtual-and-physical-worlds)
  - [Generalist Embodied Agents](#embodied-agents)
  - [Generalist Web Agents](#generalist-web-agents)
  - [Datasets & Benchmarks](#datasets-&-benchmarks)

---

## Generalist Agents in Both Virtual and Physical Worlds
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| May 2022 | Gato | [A Generalist Agent](https://arxiv.org/abs/2205.06175) | TMLR'22 | [Report](https://deepmind.google/discover/blog/a-generalist-agent/) |
| Feb 2024 | Interactive Agent Foundation Model | [An Interactive Agent Foundation Model](https://arxiv.org/abs/2402.05929) | ArXiv'24 | [Report](https://www.microsoft.com/en-us/research/publication/interactive-agent-foundation-model/) |



## Generalist Embodied Agents
### Vision-Language-Action (VLA) Models
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Dec 2022 | RT-1 | [RT-1: Robotics Transformer for Real-World Control at Scale](https://arxiv.org/abs/2406.09246) | RSS'23 | [Project](https://robotics-transformer1.github.io/) |
| July 2023 | RT-2 | [RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control](https://arxiv.org/abs/2307.15818) | ArXiv'23 | [Project](https://robotics-transformer2.github.io/) |
| Nov 2023 | LEO | [An embodied generalist agent in 3d world](https://arxiv.org/abs/2311.12871) | ICML'24 | [Project](https://embodied-generalist.github.io/) |
| Mar 2024 | 3D-VLA | [3D-VLA: A 3D Vision-Language-Action Generative World Model](https://arxiv.org/abs/2403.09631) | ICML'24 | [Project](https://vis-www.cs.umass.edu/3dvla) |
| May 2024 | Octo | [Octo: An Open-Source Generalist Robot Policy](https://arxiv.org/abs/2403.09618) | ArXiv'24 | [Project](https://octo-models.github.io/) |
| Jun 2024 | OpenVLA | [OpenVLA: An Open-Source Vision-Language-Action Model](https://arxiv.org/abs/2406.09246) | CORL'24 | [Project](https://openvla.github.io/) |
| Jun 2024 | LLARVA | [LLARVA: Vision-Action Instruction Tuning Enhances Robot Learning](https://arxiv.org/abs/2406.11815) | ArXiv'24 | [Project](https://llarva24.github.io/) |
| Sep 2024 | TinyVLA | [TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2409.12514) | ArXiv'24 | [Project](https://tiny-vla.github.io/) |
| Oct 2024 | GR-2 | [GR-2: A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation](https://arxiv.org/abs/2410.06158) | ArXiv'24 | [Project](https://gr2-manipulation.github.io/) |
| Oct 2024 | LAPA | [Latent Action Pretraining from Videos](https://arxiv.org/abs/2410.11758) | ArXiv'24 | [Project](https://latentactionpretraining.github.io/) |
| Oct 2024 | π0 | [π0: A Vision-Language-Action Flow Model for General Robot Control](https://arxiv.org/abs/2410.24164) | ArXiv'24 | [Project](https://www.physicalintelligence.company/blog/pi0) |
| Nov 2024 | CogACT | [CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation](https://arxiv.org/abs/2411.xxxxx) | ArXiv'24 | [Project](https://cogact.github.io/) |
| Nov 2024 | RT-Affordance | [RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation](https://arxiv.org/abs/2411.02704) | ArXiv'24 | [Project](https://snasiriany.me/rt-affordance) |
| Dec 2024 | Diffusion-VLA | [Diffusion-VLA: Scaling Robot Foundation Models via Unified Diffusion and Autoregression](https://arxiv.org/abs/2412.03293) | ArXiv'24 | [Project](https://diffusion-vla.github.io/) |
| Dec 2024 | RoboVLMs | [Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models](https://arxiv.org/abs/2412.14058) | ArXiv'24 | [Project](https://robovlms.github.io/) |
| Dec 2024 | Moto | [Moto: Latent Motion Token as the Bridging Language for Robot Manipulation](https://arxiv.org/abs/2412.04445) | ArXiv'24 | [Project](https://chenyi99.github.io/moto/) |
| Dec 2024 | TraceVLA | [TraceVLA: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies](https://arxiv.org/abs/2412.10345) | ArXiv'24 | [Project](https://tracevla.github.io/) |
| Dec 2024 | NaVILA | [NaVILA: Legged Robot Vision-Language-Action Model for Navigation](https://arxiv.org/abs/2412.04453) | ArXiv'24 | [Project](https://navila-bot.github.io/) |


### Other Generalist Policies

|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Sep 2024 | RUMs | [Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments](https://arxiv.org/abs/2409.05865) | ArXiv'24 | [Project](https://robotutilitymodels.com/) |
| Sep 2024 | FLaRe | [FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning](https://arxiv.org/abs/2409.16578) | ArXiv'24 | [Project](https://robot-flare.github.io/) |
| Oct 2024 | Law in IL | [Data Scaling Laws in Imitation Learning for Robotic Manipulation](https://arxiv.org/abs/2410.18647) | ArXiv'24 | [Project](https://data-scaling-laws.github.io/) |



### Multimodal World Models
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Nov 2024 | WHALE | [WHALE: Towards Generalizable and Scalable World Models for Embodied Decision-making](https://arxiv.org/abs/2411.05619) | ArXiv'24 | [Project]() |


## Generlist Web Agents
### Generalist Agents for Simulated Worlds
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Feb 2024 | Agent-Pro | [Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization](https://arxiv.org/abs/2402.17574) | ACL'24 | [Project](https://github.com/zwq2018/Agent-Pro) |
| Dec 2023 | LARP | [LARP: Language-Agent Role Play for Open-World Games](https://arxiv.org/abs/2312.17653) | ArXiv'23 | [Project](https://miao-ai-lab.github.io/LARP/) |
| Mar 2024 | SIMA | [Scaling Instructable Agents Across Many Simulated Worlds](https://arxiv.org/abs/2404.10179) | ArXiv'24 | [Report](https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/?utm_source=twitter&utm_medium=social&utm_campaign=SIMA/) |
| Aug 2024 | Optimus-1 | [Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks](https://arxiv.org/abs/2408.03615) | ArXiv'24 | [Project](https://cybertronagent.github.io/Optimus-1.github.io/) |




### Generalist Agents for Realistic Tasks
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Feb 2023 | Toolformer | [Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/abs/2302.04761) | NeurIPS'23 | [Project]() |
| Mar 2023 | RCI | [Language Models can Solve Computer Tasks](https://arxiv.org/abs/2303.17491) | ArXiv'23 | [Project](https://posgnu.github.io/rci-web/) |
| Mar 2023 | HuggingGPT | [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](https://arxiv.org/abs/2303.17580) | ArXiv'23 | [Project](https://huggingface.co/spaces/microsoft/HuggingGPT) |
| May 2023 | Pix2Act | [From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces](https://arxiv.org/abs/2306.00245) | NeurIPS'23 | [Project](https://github.com/google-deepmind/pix2act) |
| Jul 2023 | WebAgent | [A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis](https://arxiv.org/abs/2307.12856) | ICLR'24 | [Project]() |
| Sep 2023 | LASER | [LLM Agent with State-Space Exploration for Web Navigation](https://arxiv.org/abs/2309.08172) | ArXiv'23 | [Project]([https://github.com/laser-agent/laser](https://github.com/Mayer123/LASER)) |
| Sep 2023 | Auto-GUI | [You Only Look at Screens: Multimodal Chain-of-Action Agents](https://arxiv.org/abs/2309.11436) | ACL'24 | [Project](https://github.com/cooelf/Auto-GUI) |
| Sep 2023 | Agents | [Agents: An Open-source Framework for Autonomous Language Agents](https://arxiv.org/abs/2309.07870) | ArXiv'23 | [Project](https://github.com/aiwaves-cn/agents) |
| Oct 2023 | AgentTuning | [AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://arxiv.org/abs/2310.12823) | ArXiv'23 | [Project](https://thudm.github.io/AgentTuning/) |
| Dec 2023 | CogAgent | [CogAgent: A Visual Language Model for GUI Agents](https://arxiv.org/abs/2312.08914) | CVPR'24 | [Project](https://github.com/THUDM/CogAgent) |
| Dec 2023 | AppAgent | [AppAgent: Multimodal Agents as Smartphone Users](https://arxiv.org/abs/2312.13771) | ArXiv'23 | [Project](https://appagent-official.github.io/) |
| Dec 2023 | CLOVA | [CLOVA: A Closed-LOop Visual Assistant with Tool Usage and Update](https://arxiv.org/abs/2312.10908) | CVPR 2024 | [Project](https://clova-tool.github.io/) |
| Jan 2024 | SeeAct | [GPT-4V(ision) is a Generalist Web Agent, if Grounded](https://arxiv.org/abs/2401.01614) | ICML'24 | [Project](https://osu-nlp-group.github.io/SeeAct/) |
| Jan 2024 | Mobile-Agent | [Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://arxiv.org/abs/2401.16158) | ArXiv'24 | [Project](https://github.com/X-PLUG/MobileAgent) |
| Jan 2024 | WebVoyager | [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://arxiv.org/abs/2401.13919) | ACL'24 | [Project](https://github.com/web-voyager/webvoyager) |
| Jan 2024 | SeeClick | [SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents](https://arxiv.org/abs/2401.10935) | ArXiv'24 | [Project](https://github.com/njucckevin/SeeClick)|
| Jan 2024 | Mobile-Agent | [Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception](https://arxiv.org/abs/2401.16158) | ArXiv'24 | [Project](https://github.com/X-PLUG/MobileAgent) |
| Feb 2024 | OS-Copilot | [OS-Copilot: Towards Generalist Computer Agents with Self-Improvement](https://arxiv.org/abs/2402.07456) | ArXiv'24 | [Project](https://os-copilot.github.io/) |
| Feb 2024 | ScreenAgent | [ScreenAgent: A Vision Language Model-driven Computer Control Agent](https://arxiv.org/abs/2402.07945) | ArXiv'24 | [Project](https://github.com/niuzaisheng/ScreenAgent) |
| Feb 2024 | Middleware | [Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments](https://arxiv.org/abs/2402.14672) | EMNLP'2024 | [Project]() |
| Apr 2024 | WILBUR | [WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](https://arxiv.org/abs/2404.05107) | ArXiv'24 | [Project](https://michael-lutz.github.io/WILBUR/) |
| Jul 2024 | OmniParser | [OmniParser for Pure Vision Based GUI Agent](https://arxiv.org/abs/2408.00203) | ArXiv'24 | [Project](ttps://microsoft.github.io/OmniParser/) |
| Aug 2024 | Agent Q | [Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents](https://arxiv.org/abs/2408.07199) | ArXiv'24 | [Project](https://github.com/sentient-engineering/agent-q) |
| Oct 2024 | OS-ATLAS | [OS-ATLAS: A Foundation Action Model for Generalist GUI Agents](https://arxiv.org/abs/2410.23218) | ArXiv'24 | [Project](https://osatlas.github.io/) |
| Nov 2024 | ShowUI | [ShowUI: One Vision-Language-Action Model for GUI Visual Agent](https://arxiv.org/abs/2411.17465) | ArXiv'24 | [Project](https://github.com/showlab/ShowUI/) |
| Jan 2025 | InfiGUIAgent | [InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection](https://arxiv.org/abs/2501.04575) | ArXiv'25 | [Project](https://github.com/Reallm-Labs/InfiGUIAgent) |



## Datasets & Benchmarks
### For Embodied Agents
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Oct 2023 | Open X-Embodiment | [Open X-Embodiment: Robotic Learning Datasets and RT-X Models](https://arxiv.org/abs/2310.08864) | ArXiv'24 | [Project](https://robotics-transformer-x.github.io/) |
| Dec 2024 | RoboMIND | [RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation](https://arxiv.org/abs/2412.13877) | ArXiv'24 | [Project](https://x-humanoid-robomind.github.io/) |
| Dec 2024 | VLABench | [VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks](https://arxiv.org/abs/2412.18194) | ArXiv'24 | [Project](https://vlabench.github.io/) |


### For Web Agents
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Jul 2022 | WebShop | [Towards Scalable Real-World Web Interaction with Grounded Language Agents](https://arxiv.org/abs/2207.01206) | NeurIPS'22 | [Project](https://webshop-pnlp.github.io/) |
| May 2023 | Mobile-Env | [Mobile-Env: An Evaluation Platform and Benchmark for Interactive Agents in LLM Era](https://arxiv.org/abs/2305.08144) | ArXiv'23 | [Project](https://github.com/X-LANCE/Mobile-Env) | 
| Jun 2023 | Mind2Web | [Mind2Web: Towards a Generalist Agent for the Web](https://arxiv.org/abs/2306.06070) | NeurIPS'23 | [Project](https://osu-nlp-group.github.io/Mind2Web/) |
| Jul 2023 | WebArena | [WebArena: A Realistic Web Environment for Building Autonomous Agents](https://arxiv.org/abs/2307.13854) | ICLR'24 | [Project](https://webarena.dev/) |
| Jul 2023 | ToolBench | [ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs](https://arxiv.org/abs/2307.16789) | ICLR'24 | [Project](https://github.com/OpenBMB/ToolBench) |
| Jul 2023 | AITW | [Android in the Wild: A Large-Scale Dataset for Android Device Control](https://arxiv.org/abs/2307.10088) | ArXiv'23 | [Project](https://github.com/google-research/google-research/tree/master/android_in_the_wild) |
| Aug 2023 | AgentBench | [AgentBench: Evaluating LLMs as Agents](https://arxiv.org/abs/2308.03688) | ArXiv'23 | [Project](https://llmbench.ai/) |
| Jan 2024 | VWA | [Visualwebarena: Evaluating multimodal agents on realistic visual web tasks](https://arxiv.org/abs/2401.13649) | ACL'2024 | [Project](https://jykoh.com/vwa) |
| Jan 2024 | A3 | [A3: Android Agent Arena for Mobile GUI Agents](https://arxiv.org/abs/2501.01149) | ArXiv'24 | [Project](https://yuxiangchai.github.io/Android-Agent-Arena/) |
| Feb 2024 | TravelPlanner | [Travelplanner: A benchmark for real-world planning with language agents](https://arxiv.org/abs/2402.01622) | ICML'2024 | [Project](https://osu-nlp-group.github.io/TravelPlanner/) |
| Feb 2024 | OmniACT | [OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web](https://arxiv.org/abs/2402.17553) | ArXiv'24 | [Dataset](https://huggingface.co/datasets/Writer/omniact) |
| Mar 2024 | WorkArena | [WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?](https://arxiv.org/abs/2403.07718) | ArXiv'24 | [Project](https://servicenow.github.io/WorkArena/) |
| Apr 2024 | OSWorld | [OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments](https://arxiv.org/abs/2404.07864) | ArXiv'24 | [Project](https://os-world.github.io/) |
| Jul 2024 | MMAU | [MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains](https://arxiv.org/abs/2407.18961) | ArXiv'24 | [Project](https://github.com/apple/axlearn/tree/main/docs/research/mmau) |
| Sep 2024 | WindowsAgentArena | [Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale](https://arxiv.org/abs/2409.08264) | ArXiv'24 | [Project](https://github.com/microsoft/WindowsAgentArena) |




### General Benchmarks
|  Date |       keywords          | Paper                                                                                                                                                                               | Publication | Others |
| :-----: | :------------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------: 
| Aug 2024 | VisualAgentBench | [VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents](https://arxiv.org/abs/2408.06327) | ArXiv'24 | [Project](https://github.com/THUDM/VisualAgentBench/) |



## 🌷
We always welcome contributions. If you find any interesting papers that are not included in this collection, feel free to open a pull request.

For any questions or suggestions, please contact [Yongyuan Liang](https://cheryyunl.github.io/) or [Ruihan Yang](https://rchalyang.github.io/).
